# 回归模型的评价指标
> svm,liner regression,decision regression
## 1. 均方误差(Mean Squared Error,MSE)
观测值与真值偏差的平方和与观测次数的比值：
$$MSE=\frac{1}{m} \sum_{i=1}^{m}\left(f_{i}-y_{i}\right)^{2}$$
这就是线性回归中最常用的损失函数，线性回归过程中尽量让该损失函数最小。那么模型之间的对比也可以用它来比较。
MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度.

## 2. 均方根误差(Root Mean Squard Error，RMSE)
标准误差是均方误差的算术平方根。
标准差是用来衡量一组数自身的离散程度，而均方根误差是用来衡量观测值同真值之间的偏差，它们的研究对象和研究目的不同，但是计算过程类似。
$$RMSE=\sqrt{\frac{1}{m} \sum_{i=1}^{m}\left(f_{i}-y_{i}\right)^{2}}$$

## 3. 平均绝对误差(Mean Absolute Error，MAE)
平均绝对误差是绝对误差的平均值 ：
$$MAE=\frac{1}{m} \sum_{i=1}^{m}\left|f_{i}-y_{i}\right|$$
平均绝对误差能更好地反映预测值误差的实际情况.

## 4. R-squared
$$R^{2}=1-\frac{\sum_{i=1}^{m}\left(f_{i}-y_{i}\right)^{2}}{\sum_{i=1}^{m}\left(\overline{y_{i}}-y_{i}\right)^{2}}$$
上面分子就是我们训练出的模型预测的误差和。
下面分母就是瞎猜的误差和。（通常取观测值的平均值）

如果结果是0，就说明我们的模型跟瞎猜差不多。
如果结果是1。就说明我们模型无错误。

$R^2$ 介于0~1之间，越接近1，回归拟合效果越好，一般认为超过0.8的模型拟合优度比较高。

# 分类模型的评价指标
> LightGBM,LR,svm二分类
## 1. 混淆矩阵
## 2. F1 score
## 3. ROC和AUC(只能用于二分类)

# 多分类模型的评价指标
> knn 多分类

# 关联关系
> FP-Growth,协调过滤