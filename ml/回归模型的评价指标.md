# 回归模型的评价指标
> svm,liner regression,decision regression
## 1. 均方误差(Mean Squared Error,MSE)
观测值与真值偏差的平方和与观测次数的比值：
$$MSE=\frac{1}{m} \sum_{i=1}^{m}\left(f_{i}-y_{i}\right)^{2}$$
这就是线性回归中最常用的损失函数，线性回归过程中尽量让该损失函数最小。那么模型之间的对比也可以用它来比较。
MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度.

## 2. 均方根误差(Root Mean Squard Error，RMSE)
标准误差是均方误差的算术平方根。
标准差是用来衡量一组数自身的离散程度，而均方根误差是用来衡量观测值同真值之间的偏差，它们的研究对象和研究目的不同，但是计算过程类似。
$$RMSE=\sqrt{\frac{1}{m} \sum_{i=1}^{m}\left(f_{i}-y_{i}\right)^{2}}$$

## 3. 平均绝对误差(Mean Absolute Error，MAE)
平均绝对误差是绝对误差的平均值 ：
$$MAE=\frac{1}{m} \sum_{i=1}^{m}\left|f_{i}-y_{i}\right|$$
平均绝对误差能更好地反映预测值误差的实际情况.

## 4. R-squared
$$R^{2}=1-\frac{\sum_{i=1}^{m}\left(f_{i}-y_{i}\right)^{2}}{\sum_{i=1}^{m}\left(\overline{y_{i}}-y_{i}\right)^{2}}$$
上面分子就是我们训练出的模型预测的误差和。
下面分母就是瞎猜的误差和。（通常取观测值的平均值）

如果结果是0，就说明我们的模型跟瞎猜差不多。
如果结果是1。就说明我们模型无错误。

$R^2$ 介于0~1之间，越接近1，回归拟合效果越好，一般认为超过0.8的模型拟合优度比较高。

# 分类模型的评价指标
> LightGBM,LR,svm二分类
## 1. 混淆矩阵
混淆矩阵是监督学习中的一种可视化工具，主要用于比较分类结果和实例的真实信息。***矩阵中的每一行代表实例的预测类别，每一列代表实例的真实类别。***
- 真正(True Positive , TP)：被模型预测为正的正样本。
- 假正(False Positive , FP)：被模型预测为正的负样本。
- 假负(False Negative , FN)：被模型预测为负的正样本。
- 真负(True Negative , TN)：被模型预测为负的负样本。
----
- 真正率(True Positive Rate,TPR)：TPR=TP/(TP+FN)，即被预测为正的正样本数 /正样本实际数。
- 假正率(False Positive Rate,FPR) ：FPR=FP/(FP+TN)，即被预测为正的负样本数 /负样本实际数。
- 假负率(False Negative Rate,FNR) ：FNR=FN/(TP+FN)，即被预测为负的正样本数 /正样本实际数。
- 真负率(True Negative Rate,TNR)：TNR=TN/(TN+FP)，即被预测为负的负样本数 /负样本实际数



## 2. F1 score
## 3. ROC和AUC(只能用于二分类)

# 多分类模型的评价指标
> knn 多分类

Macro F1: 将n分类的评价拆成n个二分类的评价，计算每个二分类的F1 score，n个F1 score的平均值即为Macro F1。

Micro F1: 将n分类的评价拆成n个二分类的评价，将n个二分类评价的TP、FP、RN对应相加，计算评价准确率和召回率，由这2个准确率和召回率计算的F1 score即为Micro F1。

一般来讲，Macro F1、Micro F1高的分类效果好。Macro F1受样本数量少的类别影响大。

```
from sklearn.metrics import precision_score,recall_score

print (precision_score(y_true, y_scores,average='micro'))

其中average是参数，不同参数适用不同任务，比如二分类，多分类，多标签
```
## 1. 混淆矩阵(多分类)
[sklearn-confusion matrix example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)
```
>>> from sklearn.metrics import confusion_matrix
>>> y_true = [2, 0, 2, 2, 0, 1]
>>> y_pred = [0, 0, 2, 2, 0, 2]
>>> confusion_matrix(y_true, y_pred)
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])
# 第一行表示，0 预测为 0，0 预测为 1，0 预测为 2 的数量

# 试用seaborn进行可视化
>> import seaborn as sn
>> sn.heatmap(confusion_matrix(y_true, y_pred), annot=True)
	# annot=True，显示各个cell上的数字
```

## 2. 分类报告
```
from sklearn.metrics import classification_report
y_true = [0, 1, 2, 2, 0]
y_pred = [0, 0, 2, 1, 0]
target_names = [‘class 0’, ‘class 1’, ‘class 2’]
print(classification_report(y_true, y_pred, target_names=target_names))
```


# 关联关系
> FP-Growth,协调过滤